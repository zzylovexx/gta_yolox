{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "train_dir='train/'\n",
    "labels_dir='train_labels/'\n",
    "val_dir='val/'\n",
    "val_labels='val_labels/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_category = 'gta_car'\n",
    "class_names =  ['car']\n",
    "dataset_info = {'info': {'description': 'gta_traindataset', 'url': 'https://drive.google.com/file/d/1L4XU3rCCEwQqwIk1V419bxxZuOtsOnfQ/view', 'version': '0.0',\n",
    "                'year': 2022, 'contributor': 'nctu'}, \n",
    "                'images': [], 'annotations': [], \n",
    "                'categories': [{'supercategory': super_category, 'id': i+1, 'name': cls} for i, cls in enumerate(class_names)]}\n",
    "train_dataset = {}\n",
    "train_dataset.update(dataset_info)\n",
    "val_dataset_info = {'info': {'description': 'gta_valdataset', 'url': 'https://drive.google.com/file/d/1L4XU3rCCEwQqwIk1V419bxxZuOtsOnfQ/view', 'version': '0.0',\n",
    "                'year': 2022, 'contributor': 'nctu'}, \n",
    "                'images': [], 'annotations': [], \n",
    "                'categories': [{'supercategory': super_category, 'id': i+1, 'name': cls} for i, cls in enumerate(class_names)]}\n",
    "val_dataset={}\n",
    "val_dataset.update(val_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2coco(box_info, img_size):\n",
    "    x_min = (box_info[0] - box_info[2]/2) * img_size[1]\n",
    "    x_max = (box_info[0] + box_info[2]/2) * img_size[1]\n",
    "    y_min = (box_info[1] - box_info[3]/2) * img_size[0]\n",
    "    y_max = (box_info[1] + box_info[3]/2) * img_size[0]\n",
    "    \n",
    "    return x_min, x_max, y_min, y_max\n",
    "ann_id=1\n",
    "images_dir = os.path.join(train_dir )\n",
    "\n",
    "width=1920\n",
    "height=1080\n",
    "for idx, image_file in enumerate(os.listdir(images_dir)):\n",
    "    #height, width, _ = cv2.imread(os.path.join(images_dir, image_file)).shape\n",
    "    train_dataset['images'].append({'file_name': image_file, 'width': 1920, 'height': 1080, 'id': idx+1})\n",
    "    image_txt = image_file.replace('.jpg','.txt').replace('.png','.txt')\n",
    "    with open(os.path.join(labels_dir, image_txt), 'r') as f:\n",
    "        label_info = f.readlines()\n",
    "        for i_label in label_info:\n",
    "            label = i_label.split()\n",
    "            class_id = int(label[0])+1\n",
    "            x = float(label[1])\n",
    "            y = float(label[2])\n",
    "            w = float(label[3])\n",
    "            h = float(label[4])\n",
    "            box_info = [x, y, w, h]\n",
    "            img_size = [height, width]\n",
    "            x_min, x_max, y_min, y_max = yolo2coco(box_info, img_size)\n",
    "            box_w = max(0, x_max-x_min)\n",
    "            box_h = max(0, y_max-y_min)\n",
    "            train_dataset['annotations'].append({'segmentation': [], 'area': box_w * box_h, 'iscrowd': 0, 'image_id': idx+1, \n",
    "                                           'bbox': [x_min, y_min, box_w, box_h], 'category_id': class_id, 'id': ann_id\n",
    "                                          })\n",
    "            ann_id += 1\n",
    "\n",
    "\n",
    "\n",
    "    # if (idx%10==0):\n",
    "    #     print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_annid=1\n",
    "val_image_dir=os.path.join(val_dir)\n",
    "for idx, image_file in enumerate(os.listdir(val_image_dir)):\n",
    "    val_dataset['images'].append({'file_name': image_file, 'width': 1920, 'height': 1080, 'id': idx+1})\n",
    "    image_txt = image_file.replace('.jpg','.txt').replace('.png','.txt')\n",
    "    with open(os.path.join(val_labels, image_txt), 'r') as f:\n",
    "        label_info = f.readlines()\n",
    "        for i_label in label_info:\n",
    "            label = i_label.split()\n",
    "            class_id = int(label[0])+1\n",
    "            x = float(label[1])\n",
    "            y = float(label[2])\n",
    "            w = float(label[3])\n",
    "            h = float(label[4])\n",
    "            box_info = [x, y, w, h]\n",
    "            img_size = [height, width]\n",
    "            x_min, x_max, y_min, y_max = yolo2coco(box_info, img_size)\n",
    "            box_w = max(0, x_max-x_min)\n",
    "            box_h = max(0, y_max-y_min)\n",
    "            val_dataset['annotations'].append({'segmentation': [], 'area': box_w * box_h, 'iscrowd': 0, 'image_id': idx+1, \n",
    "                                           'bbox': [x_min, y_min, box_w, box_h], 'category_id': class_id, 'id': val_annid\n",
    "                                          })\n",
    "            val_annid += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(((train_dataset['annotations'][1])))\n",
    "#print((val_dataset['annotations']))\n",
    "rootdir=''\n",
    "annotation_dir = os.path.join(rootdir, 'annotations')\n",
    "if not os.path.exists(annotation_dir):\n",
    "    os.makedirs(annotation_dir,exist_ok=True)\n",
    "with open(os.path.join(annotation_dir, 'train.json'), 'w') as json_file:\n",
    "  json.dump(train_dataset, json_file)\n",
    "\n",
    "with open(os.path.join(annotation_dir, 'val.json'), 'w') as json_file:\n",
    "  json.dump(val_dataset, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('yolox')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2364a1b055f50530156a27e3feeb2d674e941d441fbe21a0166a06c4f8cc925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
